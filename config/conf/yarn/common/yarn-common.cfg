[configuration]
  # The raw files need to read when generating the configuration
  configuration.xsl=${config_dir}/template/configuration.xsl
  log4j.xml=${config_dir}/template/yarn/log4j.xml
  krb5.conf=${config_dir}/krb5-hadoop.conf
  excludes=${config_dir}/excludes

  [[core-site.xml]]
  # The core-site.xml config content
  fs.defaultFS=hdfs://${cluster.hdfs_cluster}

  hadoop.http.staticuser.user=yarn
  hadoop.tmp.dir=/tmp/hadoop
  io.file.buffer.size=131072

  # security authentication switch
  hadoop.security.authentication=simple
  hadoop.security.authorization=false
  hadoop.security.use-weak-http-crypto=false

  [[hdfs-site.xml]]
  # The hdfs-site.xml config content
  dfs.nameservices=${cluster.hdfs_cluster}
  dfs.ha.namenodes.${cluster.hdfs_cluster}="host0,host1"
  dfs.namenode.rpc-address.${cluster.hdfs_cluster}.host0=${hdfs.namenode.host.0}:${hdfs.namenode.base_port}
  dfs.namenode.rpc-address.${cluster.hdfs_cluster}.host1=${hdfs.namenode.host.1}:${hdfs.namenode.base_port}
  dfs.client.failover.proxy.provider.${cluster.hdfs_cluster}=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

  dfs.client.read.shortcircuit.skip.auth=true
  dfs.client.read.shortcircuit=true

  # namenode security config
  dfs.namenode.kerberos.internal.spnego.principal=HTTP/hadoop@EXAMPLE.HADOOP
  dfs.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
  dfs.namenode.kerberos.principal=hdfs/hadoop@EXAMPLE.HADOOP
  # secondary namenode security config
  dfs.secondary.namenode.kerberos.internal.spnego.principal=HTTP/hadoop@EXAMPLE.HADOOP
  dfs.secondary.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
  dfs.secondary.namenode.kerberos.principal=hdfs/hadoop@EXAMPLE.HADOOP

  # datanode security config
  dfs.datanode.keytab.file=/etc/hadoop/conf/hdfs.keytab
  dfs.datanode.kerberos.principal=hdfs/hadoop@EXAMPLE.HADOOP

  [[mapred-site.xml]]
  # The mapred-site.xml config content
  mapreduce.jobhistory.address=0.0.0.0:${historyserver.base_port}
  mapreduce.jobhistory.webapp.address=0.0.0.0:${historyserver.base_port+1}
  mapreduce.shuffle.port=${nodemanager.base_port+8}
  mapreduce.admin.user.env="LD_LIBRARY_PATH=${nodemanager.current_package_dir}/lib/native:/usr/lib"

  mapreduce.framework.name=yarn
  yarn.app.mapreduce.am.staging-dir=/tmp/hadoop-yarn/staging
  mapreduce.jobhistory.keytab=/etc/hadoop/conf/yarn.keytab
  mapreduce.jobhistory.principal=yarn/hadoop@EXAMPLE.HADOOP

  [[yarn-site.xml]]
  # The yarn-site.xml config content
  # config resourcemanager
  yarn.resourcemanager.address=${resourcemanager.host.0}:${resourcemanager.base_port}
  yarn.resourcemanager.webapp.address=${resourcemanager.host.0}:${resourcemanager.base_port+1}
  yarn.resourcemanager.scheduler.address=${resourcemanager.host.0}:${resourcemanager.base_port+2}
  yarn.resourcemanager.resource-tracker.address=${resourcemanager.host.0}:${resourcemanager.base_port+3}
  yarn.resourcemanager.admin.address=${resourcemanager.host.0}:${resourcemanager.base_port+4}
  # config nodemanager
  yarn.nodemanager.address=0.0.0.0:${nodemanager.base_port}
  yarn.nodemanager.webapp.address=0.0.0.0:${nodemanager.base_port+1}
  yarn.nodemanager.localizer.address=0.0.0.0:${nodemanager.base_port+2}
  # config proxy server
  yarn.web-proxy.address=${proxyserver.host.0}:${proxyserver.base_port+1}
  yarn.nodemanager.local-dirs=${nodemanager.data_dirs}
  yarn.nodemanager.log-dirs=${nodemanager.log_dir}
  yarn.resourcemanager.nodes.exclude-path=${resourcemanager.run_dir}/excludes

  yarn.log-aggregation-enable=true
  yarn.nodemanager.aux-services=mapreduce.shuffle
  yarn.nodemanager.aux-services.mapreduce.shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
  yarn.nodemanager.remote-app-log-dir=/var/log/hadoop-yarn/apps
  yarn.nodemanager.vmem-pmem-ratio=10
  yarn.nodemanager.log.retain-seconds=86400

  yarn.scheduler.capacity.root.queues=default
  yarn.scheduler.capacity.root.capacity=100
  yarn.scheduler.capacity.root.default.capacity=100

  # use CapacityScheduler
  yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
  # use DominantResourceCalculator to support cpu scheduling
  yarn.scheduler.capacity.resource-calculator=org.apache.hadoop.yarn.server.resourcemanager.resource.DominantResourceCalculator

  yarn.resourcemanager.keytab=/etc/hadoop/conf/yarn.keytab
  yarn.resourcemanager.principal=yarn/hadoop@EXAMPLE.HADOOP
  yarn.nodemanager.keytab=/etc/hadoop/conf/yarn.keytab
  yarn.nodemanager.principal=yarn/hadoop@EXAMPLE.HADOOP
  yarn.web-proxy.keytab=/etc/hadoop/conf/yarn.keytab
  yarn.web-proxy.principal=yarn/hadoop@EXAMPLE.HADOOP

